{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Computer Vision Lecture.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/schwaaweb/aimlds1_10-DeepLearning/blob/master/M10_A--DJ--Computer_Vision_Lecture.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "6q8rMKju89Oi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Computer Vision\n",
        "\n",
        "Images are large grids of color values. Techniques have been developed over many years with the intention of extracting information from images. This coding challenge explains one of the most common and most basic techniques, filtering via convolution.\n",
        "\n",
        "### An Image\n",
        "![Grid](https://www.dropbox.com/s/gkualdmkhsbx33s/image%20grid.png?raw=1)\n",
        "\n",
        "## Iteration\n",
        "\n",
        "Images are explored by iteration, a technique you should understand fairly well at this stage of your ML career. Iteration refers to progressing across a collection of data in an orderly fashion. Training an ML algorithm involves iterating over all of the data points in the training set and updating the model with each point.\n",
        "\n",
        "Iterating on an image typically involves visiting each point in the image. Images have a height and a width, so there are two dimensions to iterate over, $x$ and $y$. The order of iteration is extremely important! Different results occur depending on if the image is iterated in a row-major fashion or a column-major fashion.\n",
        "\n",
        "![Image iteration](https://www.lucidchart.com/publicSegments/view/e611d1b5-681c-4d5d-8565-1d1dc19f9ea0/image.png)\n",
        "\n",
        "## Convolution\n",
        "\n",
        "Many image processing techniques depend on this basic building block: convolution. Image convolution involves laying the filter \"on top\" of the image and computing the sum of the products of the overlapping values. The resulting value is stored in a new image. The filter (or mask) is moved by one pixel, and the process is repeated across the entire image.\n",
        "\n",
        "$C_{i,j} = \\sum_{F_{x,y}}{ I_{i-x,j-y}F_{x,y}}$\n",
        "\n",
        "## Filtering\n",
        "\n",
        "Convolution is always performed with a filter, mask, or kernel: typically a $k \\times k$ matrix where $k$ is odd. This gives the filter an obvious center, which is used to compute the combination of the filter with the image at each coordinate of the image.\n",
        "\n",
        "Filters include:\n",
        "* [Gaussian](https://en.wikipedia.org/wiki/Kernel_(image_processing))\n",
        "* [Hessian](https://en.wikipedia.org/wiki/Hessian_matrix)\n",
        "* [Laplacian](https://homepages.inf.ed.ac.uk/rbf/HIPR2/log.htm)\n",
        "* [Difference of Gaussian](https://en.wikipedia.org/wiki/Difference_of_Gaussians)\n",
        "\n",
        "## Rotation, Translation, and Scale Invariance\n",
        "\n",
        "## Scale Space\n",
        "\n",
        "A given image exists in a particular scale space - that is, the only data recorded in the image exists at each particular coordinate. Filters like those above produce interesting features only in the scale space of the original image - usually very small and uninformative to those observing the image. In order to detect features that are larger than single-pixel relationships, the image can be converted to a scale space image, or image pyramid.\n",
        "\n",
        "![Scale Space Image](https://www.lucidchart.com/publicSegments/view/ce6e3ac3-7274-4440-b3c4-23ae5c68ba53/image.png)\n",
        "\n",
        "Through convolution with a Gaussian kernel with $\\sigma = 1/2$, followed by an image operation called subsampling, the image can be shrunk.\n",
        "\n",
        "#### Subsampling\n",
        "\n",
        "Create a new image where each pixel $p_{i,j} = f(I,i,j)$ where $f(I,i,j) = \\frac{I_{2i,2j}+I_{2i+1,2j}+I_{i,2j}+I_{i,2j+1}}{4}$. This image is exactly 1/2 the size of the original image. Assuming the original image was previously smoothed by the appropriate Gaussian kernel, no information is lost. The new image is identical to the original image, presenting features $2x$ as large.\n",
        "\n",
        "\n",
        "# Feature Vectors and Mapping\n",
        "\n",
        "Finally, a set of regions discovered through a combination of the above techniques can be bagged or mapped into a group. Training algorithms then identify which groups of features belong to specific object classes, leading to the previous state of the art in image recognition systems.\n"
      ]
    },
    {
      "metadata": {
        "id": "opDa3v3QqEUf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Assignment: Compute the convolution of the image provided in the CC with the following DoG Filter:\n",
        "\n",
        "dog_filter = np.array([[1,1,1,1,1],[1,-3,-3,-3,1],[1,-3,8,-3,1],[1,-3,-3,-3,1],[1,1,1,1,1]])\n",
        "\n",
        "# Display the image with matplotlib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pz6Bo8Z-44AR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Stretch goal"
      ]
    },
    {
      "metadata": {
        "id": "BDE9fH2Z45Im",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compute the convolution of the above image and the dog_filter through all of the scale space levels that the dog_filter fits inside of\n",
        "\n",
        "# Display the image pyramid with matplotlib"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}