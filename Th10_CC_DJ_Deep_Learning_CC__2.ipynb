{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Th10_CC--DJ--Deep_Learning_CC_#2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/schwaaweb/aimlds1_10-DeepLearning/blob/master/Th10_CC_DJ_Deep_Learning_CC__2.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "MuqomGj-WkF-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Softmax\n",
        "\n",
        "The Softmax Function is the final step in a CNN, it takes the outputs from the final layer of neurons and transforms them to be probability values between 0 and 1. In this way, instead of a vector of voting weights, we end up with a vector of probabilities where there is a single probability for each label/class. This is how our CNN makes its final classification predictions.\n",
        "\n",
        "From Wikipedia: [Softmax Function](https://en.wikipedia.org/wiki/Softmax_function)\n",
        "\n",
        "\"The Softmax Function... is a generalization of the logistic function that \"squashes\" a K-dimensional vector of arbitrary real values to a K-dimensional vector of real values, where each entry is in the range (0, 1), and all the entries add up to 1.\"\n",
        "\n",
        "$S(y_i) = \\frac{e^{y_i}}{\\sum_{j=1}^Je^{y_j}}$\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "9BOIVMc5WlyX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Do It\n",
        "\n",
        "Write your own softmax function from scratch that will work on both 1-D and 2-D matrices. \n",
        "\n",
        "The following inputs should yield the given outputs:\n",
        "\n",
        "### 1-D input: \n",
        "\n",
        "$\\begin{bmatrix}\n",
        "  1 & 2 & 3 & 6 \\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "### 1-D output: \n",
        "\n",
        " Notice that the values in this matrix add up to 1 and are scaled exponentially.\n",
        "\n",
        "$\\begin{bmatrix}\n",
        "  0.00626879 & 0.01704033 & 0.04632042 & 0.93037047 \\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "### 2-D input:\n",
        "\n",
        "$\\begin{bmatrix}\n",
        "  1 & 2 & 3 & 6 \\\\\n",
        "  2 & 4 & 5 & 6 \\\\\n",
        "  3 & 8 & 7 & 6 \\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "### 2-D output:\n",
        "\n",
        "Notice that each row in the 2-D output adds up to 1. \n",
        "\n",
        "$\\begin{bmatrix}\n",
        "  0.00626879 & 0.01704033 &  0.04632042 & 0.93037045] \\\\\n",
        "  0.01203764 & 0.08894681 & 0.24178252 & 0.657233 \\\\\n",
        "   0.00626879 & 0.01704033 & 0.04632042 & 0.93037045 \\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "CV3Omo3bWe-K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "softmax1d = lambda y : np.exp(y)/np.sum(np.exp(y))\n",
        "\n",
        "oneD = [1.0, 2.0, 3.0, 6.0]\n",
        "twoD = [[1.0,2.0,3.0,6.0],[2.0,4.0,5.0,6.0], [3.0,8.0,7.0,6.0]]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4C6DU9c_zklT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "74082e16-fa58-4d75-90d8-c4d78f5348b2"
      },
      "cell_type": "code",
      "source": [
        "softmax1d(oneD)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00626879, 0.01704033, 0.04632042, 0.93037047])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "0MJtmqbHzw8S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9f0dc62f-a065-45e2-94b7-4583aff8f221"
      },
      "cell_type": "code",
      "source": [
        "print(softmax1d(twoD[0]))\n",
        "print(softmax1d(twoD[1]))\n",
        "print(softmax1d(twoD[2]))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.00626879 0.01704033 0.04632042 0.93037047]\n",
            "[0.01203764 0.08894682 0.24178252 0.65723302]\n",
            "[0.00446236 0.66227241 0.24363641 0.08962882]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vSU5CYH-05ou",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output = []\n",
        "for n in range(3):\n",
        "  #[softmax1d(twoD[n]) for two in twoD]\n",
        "  output.append(softmax1d(twoD[n]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ncv4QAYa3SYE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "645c6917-c764-482b-d495-00659c5603fa"
      },
      "cell_type": "code",
      "source": [
        "output"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.00626879, 0.01704033, 0.04632042, 0.93037047]),\n",
              " array([0.01203764, 0.08894682, 0.24178252, 0.65723302]),\n",
              " array([0.00446236, 0.66227241, 0.24363641, 0.08962882])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "F3i1FWcZ_1je",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def twoD_max(arry):\n",
        "  output = []\n",
        "  for n in range(3):\n",
        "    output.append(softmax1d(arry[n]))\n",
        "    \n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FfdWets14lVN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "12d2b46c-54fe-4441-bb5b-645f81fb8016"
      },
      "cell_type": "code",
      "source": [
        "twoD_max(twoD)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.00626879, 0.01704033, 0.04632042, 0.93037047]),\n",
              " array([0.01203764, 0.08894682, 0.24178252, 0.65723302]),\n",
              " array([0.00446236, 0.66227241, 0.24363641, 0.08962882])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "_CKXXNd65GKy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}